{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5dfc7c7",
   "metadata": {},
   "source": [
    "# 2020-2022 date predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ba7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_20_22 = pd.read_csv(\"data/cleaned_projects_20_22.csv\")\n",
    "# print(text_20_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f074c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_20_22.columns)\n",
    "# print(text_20_22.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9693daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# # 1. 过滤非空 description\n",
    "# df = text_20_22[text_20_22['description'].notna()]\n",
    "\n",
    "# # 2. 清洗多余空格\n",
    "# df['description'] = df['description'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# # 3. 拆分为句子\n",
    "# df['sentences'] = df['description'].apply(sent_tokenize)\n",
    "\n",
    "# # 4. 扁平化为句子列表\n",
    "# all_sentences_20_22 = df['sentences'].explode().tolist()\n",
    "\n",
    "# # 5. 编码\n",
    "# sentence_vecs_20_21 = sbert_model.encode(all_sentences_20_22, show_progress_bar=True, batch_size=32, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cf78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sentence_vecs_20_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db9839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataFrame + merge back to main list\n",
    "# vec_df = pd.DataFrame(sentence_vecs_20_21)\n",
    "# vec_df.columns = [f'sbert_{i}' for i in range(vec_df.shape[1])]\n",
    "# df_vectors = pd.concat([df.reset_index(drop=True), vec_df], axis=1)\n",
    "# print(df_vectors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90912c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vectors.to_parquet('sbert_encoded_data_22.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d564f",
   "metadata": {},
   "source": [
    "开始测试2020-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9fd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e5154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 加载模型\n",
    "kmeans = joblib.load(\"kmean_model_original.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a38bb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:27700>\n",
       "Name: OSGB36 / British National Grid\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: United Kingdom (UK) - offshore to boundary of UKCS within 49°45'N to 61°N and 9°W to 2°E; onshore Great Britain (England, Wales and Scotland). Isle of Man onshore.\n",
       "- bounds: (-9.01, 49.75, 2.01, 61.01)\n",
       "Coordinate Operation:\n",
       "- name: British National Grid\n",
       "- method: Transverse Mercator\n",
       "Datum: Ordnance Survey of Great Britain 1936\n",
       "- Ellipsoid: Airy 1830\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoa_label_22 = gpd.read_file(\"data/gentri_data/all_stru_data_20_22.shp\")\n",
    "lsoa_label_22.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2d2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['site_name', 'decision_date', 'valid_date', 'polygon', 'wgs84_polygon',\n",
      "       'description', 'borough', 'street_name', 'polygon.geometries',\n",
      "       'polygon.type',\n",
      "       ...\n",
      "       'sbert_374', 'sbert_375', 'sbert_376', 'sbert_377', 'sbert_378',\n",
      "       'sbert_379', 'sbert_380', 'sbert_381', 'sbert_382', 'sbert_383'],\n",
      "      dtype='object', length=401)\n"
     ]
    }
   ],
   "source": [
    "sbert_data_22 = pd.read_parquet(\"sbert_encoded_data_22.parquet\")\n",
    "print(sbert_data_22.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a93baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.cluster_centers_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f718cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\dissertation\\project\\housing_feature_gentrification\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "target_dtype = kmeans.cluster_centers_.dtype  # 自动匹配类型\n",
    "\n",
    "sbert_columns = [f\"sbert_{i}\" for i in range(384)]\n",
    "n_samples = len(sbert_data_22)\n",
    "\n",
    "# 创建 float64（或 float32）矩阵\n",
    "X_np = np.zeros((n_samples, 384), dtype=target_dtype)\n",
    "\n",
    "for i, col in enumerate(sbert_columns):\n",
    "    X_np[:, i] = sbert_data_22[col].values.astype(target_dtype)\n",
    "\n",
    "# ✅ 最终 predict 不再报错\n",
    "sbert_data_22[\"cluster\"] = kmeans.predict(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97eee22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['site_name', 'decision_date', 'valid_date', 'polygon', 'wgs84_polygon',\n",
      "       'description', 'borough', 'street_name', 'polygon.geometries',\n",
      "       'polygon.type',\n",
      "       ...\n",
      "       'sbert_375', 'sbert_376', 'sbert_377', 'sbert_378', 'sbert_379',\n",
      "       'sbert_380', 'sbert_381', 'sbert_382', 'sbert_383', 'cluster'],\n",
      "      dtype='object', length=402)\n"
     ]
    }
   ],
   "source": [
    "print(sbert_data_22.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772f4be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lsoa_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 统计每个 LSOA 中各个 cluster 的数量\u001b[39;00m\n\u001b[32m      2\u001b[39m cluster_counts = (\n\u001b[32m      3\u001b[39m     \u001b[43msbert_data_22\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlsoa_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcluster\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     .size()\n\u001b[32m      6\u001b[39m     .unstack(fill_value=\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 转为占比（按行标准化）\u001b[39;00m\n\u001b[32m     10\u001b[39m cluster_props = cluster_counts.div(cluster_counts.sum(axis=\u001b[32m1\u001b[39m), axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dissertation\\project\\housing_feature_gentrification\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dissertation\\project\\housing_feature_gentrification\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dissertation\\project\\housing_feature_gentrification\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'lsoa_code'"
     ]
    }
   ],
   "source": [
    "# 统计每个 LSOA 中各个 cluster 的数量\n",
    "cluster_counts = (\n",
    "    sbert_data_22\n",
    "    .groupby([\"lsoa_code\", \"cluster\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# 转为占比（按行标准化）\n",
    "cluster_props = cluster_counts.div(cluster_counts.sum(axis=1), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
