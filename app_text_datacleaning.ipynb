{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0f3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append('functions')\n",
    "import preprocessing_fncs as ppf\n",
    "import elastic_search_fncs as esf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbbbb4",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b1628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# Details of the dataset\n",
    "db_host = 'https://athena.london.gov.uk'\n",
    "db_user = 'odbc_readonly'\n",
    "db_pass = 'odbc_readonly'\n",
    "db_port = '10099'\n",
    "db_name = 'gla-ldd-external'\n",
    "\n",
    "# Creates connection to the dataset\n",
    "es = Elasticsearch(\n",
    "    [f\"{db_host}:{db_port}\"],\n",
    "    basic_auth=(db_user, db_pass),\n",
    "    verify_certs=True,\n",
    "    ca_certs='athena_es_full_chain.crt'\n",
    ")\n",
    "\n",
    "# Check connection\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")\n",
    "else:\n",
    "    print(\"Could not connect to Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d08bb",
   "metadata": {},
   "source": [
    "# Get the data from 2015 to 2019\n",
    "\n",
    "## Existing Residential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            # valid data between 2015-019\n",
    "                            \"valid_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                # The conditions that should be met\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_existing_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_proposed_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1 # At least meet one of the condition\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"valid_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all = pd.concat(all_years_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0144751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9727, 15)\n",
      "      site_name valid_date                                 polygon.geometries  \\\n",
      "0          None 2015-07-20  [{'coordinates': [[[525219.5, 191405.95], [525...   \n",
      "1     101 - 109 2015-11-11  [{'coordinates': [[[516873.0468631, 179643.639...   \n",
      "2               2015-12-21  [{'coordinates': [[[531625.2932364, 185303.246...   \n",
      "3  Oculus House 2015-09-21  [{'coordinates': [[[544276.1, 184398.4], [5442...   \n",
      "4             3 2015-02-23  [{'coordinates': [[[517123.7478508, 181282.847...   \n",
      "\n",
      "         polygon.type                          wgs84_polygon.coordinates  \\\n",
      "0  GeometryCollection  [[[-0.193111, 51.6075766], [-0.1929922, 51.607...   \n",
      "1  GeometryCollection  [[[-0.3174902, 51.503653], [-0.3172725, 51.503...   \n",
      "2  GeometryCollection  [[[-0.10294429999999999, 51.5512749], [-0.1029...   \n",
      "3  GeometryCollection  [[[0.0790239, 51.540053], [0.0790787, 51.54002...   \n",
      "4  GeometryCollection  [[[-0.3133355, 51.5183339], [-0.31333639999999...   \n",
      "\n",
      "  wgs84_polygon.type  total_no_proposed_residential_units  \\\n",
      "0            Polygon                                    5   \n",
      "1            Polygon                                   13   \n",
      "2            Polygon                                    1   \n",
      "3            Polygon                                  274   \n",
      "4            Polygon                                    5   \n",
      "\n",
      "   total_no_existing_residential_units  \\\n",
      "0                                    1   \n",
      "1                                    5   \n",
      "2                                    1   \n",
      "3                                   13   \n",
      "4                                    1   \n",
      "\n",
      "                                         description               borough  \\\n",
      "0  Demolition of existing house and erection of a...                Barnet   \n",
      "1  Redevelopment of the site to provide 12 flats ...                Ealing   \n",
      "2  Demolition of the existing house, and the erec...             Islington   \n",
      "3  Demolition of existing building and redevelopm...  Barking and Dagenham   \n",
      "4  Conversion of single family dwelling house int...                Ealing   \n",
      "\n",
      "             street_name polygon.coordinates  wgs84_polygon  polygon  year  \n",
      "0              The Drive                 NaN            NaN      NaN  2015  \n",
      "1      Northfield Avenue                 NaN            NaN      NaN  2015  \n",
      "2  Highbury Terrace Mews                 NaN            NaN      NaN  2015  \n",
      "3         CAMBRIDGE ROAD                 NaN            NaN      NaN  2015  \n",
      "4          Mortimer Road                 NaN            NaN      NaN  2015  \n"
     ]
    }
   ],
   "source": [
    "print(df_london_all.shape)\n",
    "print(df_london_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692be418",
   "metadata": {},
   "source": [
    "## Proposed Residential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0968cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df2 = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            # desition data between 2015-019\n",
    "                            \"decision_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                # The conditions that should be met\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_existing_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_proposed_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1 # At least meet one of the condition\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"decision_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df2.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all2 = pd.concat(all_years_df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea10114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31718, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_london_all2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8dd4c",
   "metadata": {},
   "source": [
    "There is a large gap between the decision date and the valid date.\n",
    "\n",
    "1. change into decision date?\n",
    "\n",
    "2. stick to valid date but change the range to a longer time period?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcb79a",
   "metadata": {},
   "source": [
    "## All applications between 2015 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef5f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13084\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13084\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13084\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13084\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13084\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df3 = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"valid_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"valid_date\",\n",
    "            \"decision_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df3.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all3 = pd.concat(all_years_df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa47e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192685, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df_london_all3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1348105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_all3.to_csv(\"data/cleaned_projects_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3112f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Select the text (description column, delete NA lines)\n",
    "- Clean the text (excessive spaces and special characters)\n",
    "- Split the descriptions into sentences\n",
    "- Vectorizes sentences using SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537ba34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import joblib\n",
    "import os\n",
    "import nltk\n",
    "# nltk.download('punkt')      # Normal Sentence Segmentation Model\n",
    "# nltk.download('punkt_tab')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cc9bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site_name', 'decision_date', 'valid_date', 'polygon.geometries',\n",
       "       'polygon.type', 'wgs84_polygon.coordinates', 'wgs84_polygon.type',\n",
       "       'description', 'borough', 'street_name',\n",
       "       'total_no_proposed_residential_units',\n",
       "       'total_no_existing_residential_units', 'polygon', 'wgs84_polygon',\n",
       "       'polygon.coordinates', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconfirm the columns\n",
    "df_london_all3.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6932556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a new copy\n",
    "df = df_london_all3.copy()\n",
    "# keep only the non-empty text\n",
    "df = df[df['description'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02e4edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excessive spaces and special characters\n",
    "df['description'] = df['description'].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4369d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "df['sentences'] = df['description'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e51fbad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten all the sentences\n",
    "all_sentences = df['sentences'].explode().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ff8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09b0c6",
   "metadata": {},
   "source": [
    "！This took too much time (around 40 mins), consider moving to google colab.\n",
    "\n",
    "Here used paraphrase-MiniLM-L6-v2 to minimize the time, can change into 768 vector in colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53f9e4730064d17b69b8bc85c7519d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings cached!\n"
     ]
    }
   ],
   "source": [
    "# encode all sentences (with caching)\n",
    "BATCH_SIZE = 64\n",
    "CACHE_FILE = 'sbert_vectors.pkl'\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(\"Loading cached embeddings...\")\n",
    "    sentence_embeddings = joblib.load(CACHE_FILE)\n",
    "else:\n",
    "    print(\"Encoding...\")\n",
    "    sentence_embeddings = model.encode(\n",
    "        all_sentences,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    joblib.dump(sentence_embeddings, CACHE_FILE)\n",
    "    print(\"Embeddings cached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43f61a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192584/192584 [00:01<00:00, 160212.37it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_idx = 0\n",
    "final_vectors = []\n",
    "\n",
    "for sent_list in tqdm(df['sentences']):\n",
    "    count = len(sent_list)\n",
    "    if count == 0:\n",
    "        final_vectors.append(np.zeros(model.get_sentence_embedding_dimension()))\n",
    "    else:\n",
    "        vecs = sentence_embeddings[emb_idx: emb_idx + count]\n",
    "        final_vectors.append(np.mean(vecs, axis=0))\n",
    "        emb_idx += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame + merge back to main list\n",
    "vec_df = pd.DataFrame(final_vectors)\n",
    "vec_df.columns = [f'sbert_{i}' for i in range(vec_df.shape[1])]\n",
    "df_vectors = pd.concat([df.reset_index(drop=True), vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "533da2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy\n",
    "df_vectors.to_parquet('sbert_encoded_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              site_name decision_date valid_date  \\\n",
      "0                          2016-05-26 2015-06-12   \n",
      "1      Residential Unit    2015-10-28 2015-06-23   \n",
      "2                          2015-05-12 2015-04-03   \n",
      "3  McDonalds Restaurant    2015-07-03 2015-04-15   \n",
      "4                          2015-10-19 2015-08-24   \n",
      "\n",
      "                                  polygon.geometries        polygon.type  \\\n",
      "0  [{'coordinates': [[[530673.9038811, 183924.601...  GeometryCollection   \n",
      "1  [{'coordinates': [[[529220.0027867, 186434.103...  GeometryCollection   \n",
      "2  [{'coordinates': [[[524377.95, 188031.85], [52...  GeometryCollection   \n",
      "3  [{'coordinates': [[[514258.2428256, 180238.906...  GeometryCollection   \n",
      "4  [{'coordinates': [[[531615.186, 176934.497], [...  GeometryCollection   \n",
      "\n",
      "                           wgs84_polygon.coordinates wgs84_polygon.type  \\\n",
      "0  [[[-0.11717000000000001, 51.5391065], [-0.1171...            Polygon   \n",
      "1  [[[-0.137201, 51.5619933], [-0.137201699999999...            Polygon   \n",
      "2  [[[-0.20645229999999998, 51.57744], [-0.206366...            Polygon   \n",
      "3  [[[-0.3549546, 51.5095373], [-0.3549082, 51.50...            Polygon   \n",
      "4  [[[-0.1062124, 51.4760699], [-0.10629659999999...            Polygon   \n",
      "\n",
      "                                         description    borough  \\\n",
      "0  Certificate of Lawfulness in connection with e...  Islington   \n",
      "1  Substantial demolition of existing residential...  Islington   \n",
      "2  Single storey rear extension with a proposed d...     Barnet   \n",
      "3  Replacement of a 3m advertising pole with a 5m...     Ealing   \n",
      "4  Change of use from Class A1 retail unit to Cla...    Lambeth   \n",
      "\n",
      "          street_name  ...  sbert_374  sbert_375  sbert_376  sbert_377  \\\n",
      "0     Caledonian Road  ...   0.008921   0.130161   0.219602  -0.014286   \n",
      "1      Tremlett Grove  ...   0.272648   0.001166  -0.155466   0.026316   \n",
      "2  Golders Green Road  ...   0.389154   0.305840  -0.198819   0.084777   \n",
      "3       Uxbridge Road  ...   0.231106  -0.687721   0.023157   0.453250   \n",
      "4       Cromwell Road  ...   0.106714  -0.163149  -0.066535  -0.397721   \n",
      "\n",
      "  sbert_378  sbert_379 sbert_380  sbert_381  sbert_382  sbert_383  \n",
      "0  0.212071   0.304656 -0.220029   0.218034   0.095819   0.010704  \n",
      "1  0.633962   0.225428 -0.073187   0.433726  -0.363806   0.010348  \n",
      "2  0.277645   0.031429 -0.068282   0.371867  -0.242161   0.271578  \n",
      "3  0.135838   0.114552 -0.145499  -0.024457  -0.318737   0.408597  \n",
      "4  0.085191   0.384984  0.314905  -0.135224   0.064136  -0.040522  \n",
      "\n",
      "[5 rows x 401 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_vectors.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
