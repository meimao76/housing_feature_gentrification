{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0f3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append('functions')\n",
    "import preprocessing_fncs as ppf\n",
    "import elastic_search_fncs as esf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbbbb4",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b1628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# Details of the dataset\n",
    "db_host = 'https://athena.london.gov.uk'\n",
    "db_user = 'odbc_readonly'\n",
    "db_pass = 'odbc_readonly'\n",
    "db_port = '10099'\n",
    "db_name = 'gla-ldd-external'\n",
    "\n",
    "# Creates connection to the dataset\n",
    "es = Elasticsearch(\n",
    "    [f\"{db_host}:{db_port}\"],\n",
    "    basic_auth=(db_user, db_pass),\n",
    "    verify_certs=True,\n",
    "    ca_certs='athena_es_full_chain.crt'\n",
    ")\n",
    "\n",
    "# Check connection\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")\n",
    "else:\n",
    "    print(\"Could not connect to Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d08bb",
   "metadata": {},
   "source": [
    "# Get the data from 2015 to 2019\n",
    "\n",
    "## Existing Residential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fc715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\2830067377.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            # valid data between 2015-019\n",
    "                            \"valid_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                # The conditions that should be met\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_existing_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_proposed_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1 # At least meet one of the condition\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"valid_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all = pd.concat(all_years_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0144751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9727, 15)\n",
      "      site_name valid_date                                 polygon.geometries  \\\n",
      "0          None 2015-07-20  [{'coordinates': [[[525219.5, 191405.95], [525...   \n",
      "1     101 - 109 2015-11-11  [{'coordinates': [[[516873.0468631, 179643.639...   \n",
      "2               2015-12-21  [{'coordinates': [[[531625.2932364, 185303.246...   \n",
      "3  Oculus House 2015-09-21  [{'coordinates': [[[544276.1, 184398.4], [5442...   \n",
      "4             3 2015-02-23  [{'coordinates': [[[517123.7478508, 181282.847...   \n",
      "\n",
      "         polygon.type                          wgs84_polygon.coordinates  \\\n",
      "0  GeometryCollection  [[[-0.193111, 51.6075766], [-0.1929922, 51.607...   \n",
      "1  GeometryCollection  [[[-0.3174902, 51.503653], [-0.3172725, 51.503...   \n",
      "2  GeometryCollection  [[[-0.10294429999999999, 51.5512749], [-0.1029...   \n",
      "3  GeometryCollection  [[[0.0790239, 51.540053], [0.0790787, 51.54002...   \n",
      "4  GeometryCollection  [[[-0.3133355, 51.5183339], [-0.31333639999999...   \n",
      "\n",
      "  wgs84_polygon.type  total_no_proposed_residential_units  \\\n",
      "0            Polygon                                    5   \n",
      "1            Polygon                                   13   \n",
      "2            Polygon                                    1   \n",
      "3            Polygon                                  274   \n",
      "4            Polygon                                    5   \n",
      "\n",
      "   total_no_existing_residential_units  \\\n",
      "0                                    1   \n",
      "1                                    5   \n",
      "2                                    1   \n",
      "3                                   13   \n",
      "4                                    1   \n",
      "\n",
      "                                         description               borough  \\\n",
      "0  Demolition of existing house and erection of a...                Barnet   \n",
      "1  Redevelopment of the site to provide 12 flats ...                Ealing   \n",
      "2  Demolition of the existing house, and the erec...             Islington   \n",
      "3  Demolition of existing building and redevelopm...  Barking and Dagenham   \n",
      "4  Conversion of single family dwelling house int...                Ealing   \n",
      "\n",
      "             street_name polygon.coordinates  wgs84_polygon  polygon  year  \n",
      "0              The Drive                 NaN            NaN      NaN  2015  \n",
      "1      Northfield Avenue                 NaN            NaN      NaN  2015  \n",
      "2  Highbury Terrace Mews                 NaN            NaN      NaN  2015  \n",
      "3         CAMBRIDGE ROAD                 NaN            NaN      NaN  2015  \n",
      "4          Mortimer Road                 NaN            NaN      NaN  2015  \n"
     ]
    }
   ],
   "source": [
    "print(df_london_all.shape)\n",
    "print(df_london_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692be418",
   "metadata": {},
   "source": [
    "## Proposed Residential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0968cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_30212\\2603484322.py:53: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df2 = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            # desition data between 2015-019\n",
    "                            \"decision_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                # The conditions that should be met\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_existing_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"application_details.residential_details.total_no_proposed_residential_units\": {\n",
    "                                \"gte\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1 # At least meet one of the condition\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"decision_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df2.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all2 = pd.concat(all_years_df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea10114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31718, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_london_all2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8dd4c",
   "metadata": {},
   "source": [
    "There is a large gap between the decision date and the valid date.\n",
    "\n",
    "1. change into decision date?\n",
    "\n",
    "2. stick to valid date but change the range to a longer time period?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcb79a",
   "metadata": {},
   "source": [
    "## All applications between 2015 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef5f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_33108\\4074234069.py:35: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n"
     ]
    }
   ],
   "source": [
    "all_years_df3 = [] # save the data into this dataframe\n",
    "\n",
    "for year in range(2015, 2020):  # 2015–2019\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                # conditions that must be met\n",
    "                \"must\": [ \n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"valid_date\": {\n",
    "                                \"gte\": f\"01/01/{year}\",\n",
    "                                \"lt\": f\"01/01/{year + 1}\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\n",
    "            \"valid_date\",\n",
    "            \"decision_date\",\n",
    "            \"borough\",\n",
    "            \"application_details.residential_details.total_no_existing_residential_units\",\n",
    "            \"application_details.residential_details.total_no_proposed_residential_units\",\n",
    "            \"street_name\",\n",
    "            \"site_name\",\n",
    "            \"polygon\", \n",
    "            \"wgs84_polygon\", # geo\n",
    "            \"description\" # main target\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Elasticsearch query\n",
    "    response = es.search(index=\"applications\", body=query, scroll=\"2m\", size=10000)\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    all_hits = []\n",
    "    all_hits.extend(hits)\n",
    "\n",
    "    while len(hits) > 0:\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = response['_scroll_id']\n",
    "        hits = response['hits']['hits']\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    df_raw = pd.json_normalize(all_hits)\n",
    "    df_cleaned = ppf.format_df(df_raw)\n",
    "    df_cleaned['year'] = year\n",
    "\n",
    "    all_years_df3.append(df_cleaned)\n",
    "\n",
    "# combined all the data\n",
    "df_london_all3 = pd.concat(all_years_df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa47e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192685, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df_london_all3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3112f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Select the text (description column, delete NA lines)\n",
    "- Clean the text (excessive spaces and special characters)\n",
    "- Split the descriptions into sentences\n",
    "- Vectorizes sentences using SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ba34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d7c1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')      # 正常句子分词模型\n",
    "nltk.download('punkt_tab')  # （尽管它不是必须的，但这样能绕过特定 bug）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d98d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cc9bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site_name', 'decision_date', 'valid_date', 'polygon.geometries',\n",
       "       'polygon.type', 'wgs84_polygon.coordinates', 'wgs84_polygon.type',\n",
       "       'description', 'borough', 'street_name',\n",
       "       'total_no_proposed_residential_units',\n",
       "       'total_no_existing_residential_units', 'polygon', 'wgs84_polygon',\n",
       "       'polygon.coordinates', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconfirm the columns\n",
    "df_london_all3.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6932556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a new copy\n",
    "df = df_london_all3.copy()\n",
    "# keep only the non-empty text\n",
    "df = df[df['description'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02e4edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excessive spaces and special characters\n",
    "df['description'] = df['description'].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4369d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "df['sentences'] = df['description'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
