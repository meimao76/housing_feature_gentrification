{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7be58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import osmnx as ox # OSMnx is a Python package to get access to geospatial features from OpenStreetMap. (Boeing, G. 2024)\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611a2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LSOA code  tran_poi_count\n",
      "0  E01000007               5\n",
      "1  E01000008               1\n",
      "   LSOA code  shop_poi_count\n",
      "0  E01000005               1\n",
      "1  E01000007              13\n"
     ]
    }
   ],
   "source": [
    "## 6. POI Counts: \n",
    "# Select the number of transportation and shops in the area, \n",
    "# as they might act as crime attractors and influence crime opportunities.\n",
    "\n",
    "# read lsoa 2011 boundaries\n",
    "lsoa_gdf = gpd.read_file(\"data/gentri_data/london_gentri_labeled_25.shp\")\n",
    "\n",
    "# get poi data from open street map\n",
    "# code from osmnx website\n",
    "place = \"London, UK\"\n",
    "tags1 = {\"railway\": \"station\", \"highway\": \"bus_stop\"}  # subway stations and bus stations\n",
    "tags2 = {\"shop\": True } # shops\n",
    "gdf1 = ox.features_from_place(place, tags1)\n",
    "gdf2 = ox.features_from_place(place, tags2)\n",
    "\n",
    "# set the same crs\n",
    "tran_poi_gdf = gdf1.to_crs(lsoa_gdf.crs)\n",
    "shop_poi_gdf = gdf2.to_crs(lsoa_gdf.crs)\n",
    "\n",
    "# change all types of geospatial features into points\n",
    "shop_poi_gdf[\"geometry\"] = shop_poi_gdf.geometry.centroid\n",
    "\n",
    "# join the transportation points with the lsoas\n",
    "joined_tran = gpd.sjoin(tran_poi_gdf, lsoa_gdf, how='inner', predicate='within')\n",
    "# counts the points within each lsoa\n",
    "tran_poi_count = joined_tran.groupby('LSOA code').size().reset_index(name='tran_poi_count')\n",
    "\n",
    "# same with the shop points\n",
    "joined_shop = gpd.sjoin(shop_poi_gdf, lsoa_gdf, how='inner', predicate='within')\n",
    "shop_poi_count = joined_shop.groupby('LSOA code').size().reset_index(name='shop_poi_count')\n",
    "\n",
    "print(tran_poi_count.head(2))\n",
    "print(shop_poi_count.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00da7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# from shapely import wkt\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # ËØªÂèñ LSOA ËæπÁïå\n",
    "# lsoa_gdf = gpd.read_file(\"data/gentri_data/london_gentri_labeled_25.shp\")\n",
    "# lsoa_gdf = lsoa_gdf.to_crs(4326)\n",
    "\n",
    "# # Ëé∑Âèñ London ËæπÁïå\n",
    "# london_geom_json = ox.geocode_to_gdf(\"London, UK\").to_crs(4326).to_json()\n",
    "\n",
    "# # ËÆæÁΩÆÊü•ËØ¢Êó∂Èó¥ÁÇπÂíåÊ†áÁ≠æ\n",
    "# years = [\"2015-01-01\", \"2019-01-01\"]\n",
    "# filters = {\n",
    "#     \"tran\": \"railway=station OR highway=bus_stop\",\n",
    "#     \"shop\": \"shop=*\"\n",
    "# }\n",
    "\n",
    "# # Ê≠£Á°ÆÁöÑ endpoint\n",
    "# def get_pois_ohsome(geometry, filter_str, time_str):\n",
    "#     url = \"https://api.ohsome.org/v1/elementsFull/geometry\"  # ‚úÖ FIXED\n",
    "#     params = {\n",
    "#         \"bpolys\": geometry,\n",
    "#         \"filter\": filter_str,\n",
    "#         \"time\": time_str,\n",
    "#         \"format\": \"geojson\",\n",
    "#         \"types\": \"node,way\"\n",
    "#     }\n",
    "#     response = requests.post(url, json=params)\n",
    "#     response.raise_for_status()\n",
    "#     data = response.json()\n",
    "#     if not data[\"features\"]:\n",
    "#         print(\"‚ö†Ô∏è ÁªìÊûú‰∏∫Á©∫\")\n",
    "#         return None\n",
    "#     gdf = gpd.GeoDataFrame.from_features(data[\"features\"])\n",
    "#     gdf[\"timestamp\"] = gdf[\"properties\"].apply(lambda x: x[\"timestamp\"])\n",
    "#     return gdf.set_geometry(\"geometry\", crs=4326)\n",
    "\n",
    "# # ÁªüËÆ° LSOA Âå∫ÂÜÖÁöÑ POI Êï∞Èáè\n",
    "# def count_poi_per_lsoa(poi_gdf, lsoa_gdf, year_label):\n",
    "#     poi_gdf = poi_gdf.copy()\n",
    "#     poi_gdf[\"geometry\"] = poi_gdf.geometry.centroid\n",
    "#     joined = gpd.sjoin(poi_gdf.to_crs(lsoa_gdf.crs), lsoa_gdf, how='inner', predicate='within')\n",
    "#     grouped = joined.groupby(\"LSOA code\").size().reset_index(name=f\"count_{year_label}\")\n",
    "#     return grouped\n",
    "\n",
    "# # ‰∏ªÂæ™ÁéØ\n",
    "# results = {}\n",
    "# for key, filter_str in filters.items():\n",
    "#     for year in years:\n",
    "#         print(f\"‚è≥ Êü•ËØ¢ {key} Âú® {year} ÁöÑ POI ...\")\n",
    "#         try:\n",
    "#             poi_gdf = get_pois_ohsome(london_geom_json, filter_str, year)\n",
    "#             if poi_gdf is None:\n",
    "#                 continue\n",
    "#             year_label = f\"{key}_{year[:4]}\"\n",
    "#             count_df = count_poi_per_lsoa(poi_gdf, lsoa_gdf, year_label)\n",
    "#             results[year_label] = count_df\n",
    "#         except requests.exceptions.HTTPError as e:\n",
    "#             print(f\"‚ùå ËØ∑Ê±ÇÂ§±Ë¥•Ôºö{e}\")\n",
    "#             print(\"ÂìçÂ∫îÂÜÖÂÆπ:\", e.response.text)\n",
    "#             continue\n",
    "\n",
    "# # ÂêàÂπ∂Êï∞ÊçÆÊó∂Á°Æ‰øù key Â≠òÂú®\n",
    "# def safe_merge(df1, df2, on):\n",
    "#     if df1 is None or df2 is None or df1.empty or df2.empty:\n",
    "#         print(\"‚ö†Ô∏è Êüê‰∫õÊï∞ÊçÆ‰∏∫Á©∫ÔºåË∑≥ËøáÂêàÂπ∂\")\n",
    "#         return pd.DataFrame()\n",
    "#     return df1.merge(df2, on=on, how=\"outer\").fillna(0)\n",
    "\n",
    "# tran_df = safe_merge(results.get(\"tran_2015\"), results.get(\"tran_2019\"), on=\"LSOA code\")\n",
    "# shop_df = safe_merge(results.get(\"shop_2015\"), results.get(\"shop_2019\"), on=\"LSOA code\")\n",
    "\n",
    "# print(\"\\nüìä ‰∫§ÈÄö POI ÁªüËÆ°ÔºàÂâçÂá†Ë°åÔºâ:\")\n",
    "# print(tran_df.head())\n",
    "\n",
    "# print(\"\\nüìä ÂïÜÈì∫ POI ÁªüËÆ°ÔºàÂâçÂá†Ë°åÔºâ:\")\n",
    "# print(shop_df.head())\n",
    "\n",
    "# # ‰øùÂ≠òÊñá‰ª∂\n",
    "# if not tran_df.empty:\n",
    "#     tran_df.to_csv(\"outputs/tran_poi_counts.csv\", index=False)\n",
    "# if not shop_df.empty:\n",
    "#     shop_df.to_csv(\"outputs/shop_poi_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5515810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lsoa_model_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a272ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.merge(tran_poi_count, on=\"LSOA code\", how=\"left\")\n",
    "df_final = df_final.merge(shop_poi_count, on=\"LSOA code\", how=\"left\")\n",
    "df_final[\"tran_poi_count\"] = df_final[\"tran_poi_count\"].fillna(0).astype(int)\n",
    "df_final[\"shop_poi_count\"] = df_final[\"shop_poi_count\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a60e8230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LSOA code  residential_topn_mean  commercial_topn_mean  green_topn_mean  \\\n",
      "0  E01002714               0.760136              0.689529         0.700867   \n",
      "1  E01002771               0.781176              0.581556         0.683054   \n",
      "2  E01000220               0.906424              0.508664         0.511596   \n",
      "3  E01001220               0.669778              0.600520         0.555940   \n",
      "4  E01003187               0.349043              0.578166         0.357311   \n",
      "\n",
      "   cultural_topn_mean  infrustructure_topn_mean  gentrified       avg_den  \\\n",
      "0            0.580095                  0.756108           0  16340.515284   \n",
      "1            0.564128                  0.699904           0  12654.580134   \n",
      "2            0.580305                  0.633844           0  13904.333986   \n",
      "3            0.555096                  0.644365           0   1436.788216   \n",
      "4            0.474421                  0.488227           0  11407.115656   \n",
      "\n",
      "   pop_growth_rate  senior_per  minority_per  tran_poi_count  shop_poi_count  \n",
      "0         0.073130    8.472850     17.550059               4              32  \n",
      "1         0.006618    9.399077     32.164531               4              20  \n",
      "2         0.054458   15.202991     26.777125               2               1  \n",
      "3        -0.014105   11.295069     78.793903              10               6  \n",
      "4         0.325665    7.840261     70.611970               0               2  \n"
     ]
    }
   ],
   "source": [
    "print(df_final.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e46c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1008\n",
      "           1       0.11      0.03      0.05        60\n",
      "\n",
      "    accuracy                           0.93      1068\n",
      "   macro avg       0.52      0.51      0.51      1068\n",
      "weighted avg       0.90      0.93      0.91      1068\n",
      "\n",
      "AUROC: 0.6210648148148149\n",
      "AUPRC: 0.09624990174113471\n"
     ]
    }
   ],
   "source": [
    "features = ['pop_growth_rate', 'avg_den', 'senior_per', 'minority_per', \n",
    "            'residential_topn_mean', 'commercial_topn_mean', \n",
    "            'green_topn_mean', 'cultural_topn_mean', 'infrustructure_topn_mean',\n",
    "            'tran_poi_count', 'shop_poi_count']\n",
    "df_final['gentrified'] = df_final['gentrified'].astype(int)\n",
    "\n",
    "X = df_final[features]\n",
    "y = df_final['gentrified']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ê†∑Êú¨‰∏çÂùáË°°Â§ÑÁêÜ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                      random_state=42, \n",
    "                      eval_metric=\"aucpr\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # ÂèñÈ¢ÑÊµã‰∏∫ 1 ÁöÑÊ¶ÇÁéá\n",
    "print(\"AUROC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"AUPRC:\", average_precision_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.54        60\n",
      "           1       0.54      0.55      0.55        60\n",
      "\n",
      "    accuracy                           0.54       120\n",
      "   macro avg       0.54      0.54      0.54       120\n",
      "weighted avg       0.54      0.54      0.54       120\n",
      "\n",
      "AUROC: 0.6108333333333333\n",
      "AUPRC: 0.6059215597526756\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X = df_final[features]\n",
    "y = df_final['gentrified']\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "X_resampled_train, X_resampled_test, y_resampled_train, y_resampled_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                                                            stratify=y_resampled, \n",
    "                                                                                            test_size=0.25, \n",
    "                                                                                            random_state=42)\n",
    "\n",
    "scale_pos_weight = len(y_resampled_train[y_resampled_train == 0]) / len(y_resampled_train[y_resampled_train == 1])\n",
    "\n",
    "model_resampled = XGBClassifier(scale_pos_weight = scale_pos_weight,\n",
    "                      random_state=42, \n",
    "                      eval_metric=\"aucpr\")\n",
    "\n",
    "model_resampled.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "# Evaluate\n",
    "y_resampled_pred = model_resampled.predict(X_resampled_test)\n",
    "print(classification_report(y_resampled_test, y_resampled_pred))\n",
    "y_resampled_proba = model_resampled.predict_proba(X_resampled_test)[:, 1]  # ÂèñÈ¢ÑÊµã‰∏∫ 1 ÁöÑÊ¶ÇÁéá\n",
    "print(\"AUROC:\", roc_auc_score(y_resampled_test, y_resampled_proba))\n",
    "print(\"AUPRC:\", average_precision_score(y_resampled_test, y_resampled_proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
